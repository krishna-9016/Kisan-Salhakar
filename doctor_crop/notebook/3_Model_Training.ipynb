{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f90bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2d0972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed DataFrames from disk...\n",
      "DataFrames loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Pre-processed DataFrames ---\n",
    "print(\"Loading pre-processed DataFrames from disk...\")\n",
    "PROCESSED_DATA_DIR = '../data/processed'\n",
    "train_df = pd.read_parquet(os.path.join(PROCESSED_DATA_DIR, 'train.parquet'))\n",
    "val_df = pd.read_parquet(os.path.join(PROCESSED_DATA_DIR, 'val.parquet'))\n",
    "print(\"DataFrames loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ce0fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-creating the data pipeline...\n",
      "Data pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Recreate Data Pipeline (from previous step) ---\n",
    "print(\"Re-creating the data pipeline...\")\n",
    "# Transformations\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "# Dataset Class\n",
    "\n",
    "\n",
    "class PlantVillageDataset(Dataset):\n",
    "    def __init__(self, dataframe, class_to_idx_map, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        self.class_to_idx_map = class_to_idx_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.iloc[idx]['filepath']\n",
    "        label_str = self.df.iloc[idx]['label']\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_idx = self.class_to_idx_map[label_str]\n",
    "        return image, label_idx\n",
    "\n",
    "\n",
    "# Mappings, Datasets, and DataLoaders\n",
    "class_to_idx = {label: i for i, label in enumerate(train_df['label'].unique())}\n",
    "NUM_CLASSES = len(class_to_idx)\n",
    "\n",
    "train_dataset = PlantVillageDataset(\n",
    "    train_df, class_to_idx, transform=train_transforms)\n",
    "val_dataset = PlantVillageDataset(\n",
    "    val_df, class_to_idx, transform=val_test_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(\"Data pipeline ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6d0593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining the model architecture...\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\Punith/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.5M/20.5M [00:09<00:00, 2.17MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "EfficientNet                                            [32, 38]                  --\n",
       "├─Sequential: 1-1                                       [32, 1280, 7, 7]          --\n",
       "│    └─Conv2dNormActivation: 2-1                        [32, 32, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        (864)\n",
       "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        (64)\n",
       "│    │    └─SiLU: 3-3                                   [32, 32, 112, 112]        --\n",
       "│    └─Sequential: 2-2                                  [32, 16, 112, 112]        --\n",
       "│    │    └─MBConv: 3-4                                 [32, 16, 112, 112]        (1,448)\n",
       "│    └─Sequential: 2-3                                  [32, 24, 56, 56]          --\n",
       "│    │    └─MBConv: 3-5                                 [32, 24, 56, 56]          (6,004)\n",
       "│    │    └─MBConv: 3-6                                 [32, 24, 56, 56]          (10,710)\n",
       "│    └─Sequential: 2-4                                  [32, 40, 28, 28]          --\n",
       "│    │    └─MBConv: 3-7                                 [32, 40, 28, 28]          (15,350)\n",
       "│    │    └─MBConv: 3-8                                 [32, 40, 28, 28]          (31,290)\n",
       "│    └─Sequential: 2-5                                  [32, 80, 14, 14]          --\n",
       "│    │    └─MBConv: 3-9                                 [32, 80, 14, 14]          (37,130)\n",
       "│    │    └─MBConv: 3-10                                [32, 80, 14, 14]          (102,900)\n",
       "│    │    └─MBConv: 3-11                                [32, 80, 14, 14]          (102,900)\n",
       "│    └─Sequential: 2-6                                  [32, 112, 14, 14]         --\n",
       "│    │    └─MBConv: 3-12                                [32, 112, 14, 14]         (126,004)\n",
       "│    │    └─MBConv: 3-13                                [32, 112, 14, 14]         (208,572)\n",
       "│    │    └─MBConv: 3-14                                [32, 112, 14, 14]         (208,572)\n",
       "│    └─Sequential: 2-7                                  [32, 192, 7, 7]           --\n",
       "│    │    └─MBConv: 3-15                                [32, 192, 7, 7]           (262,492)\n",
       "│    │    └─MBConv: 3-16                                [32, 192, 7, 7]           (587,952)\n",
       "│    │    └─MBConv: 3-17                                [32, 192, 7, 7]           (587,952)\n",
       "│    │    └─MBConv: 3-18                                [32, 192, 7, 7]           (587,952)\n",
       "│    └─Sequential: 2-8                                  [32, 320, 7, 7]           --\n",
       "│    │    └─MBConv: 3-19                                [32, 320, 7, 7]           (717,232)\n",
       "│    └─Conv2dNormActivation: 2-9                        [32, 1280, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-20                                [32, 1280, 7, 7]          (409,600)\n",
       "│    │    └─BatchNorm2d: 3-21                           [32, 1280, 7, 7]          (2,560)\n",
       "│    │    └─SiLU: 3-22                                  [32, 1280, 7, 7]          --\n",
       "├─AdaptiveAvgPool2d: 1-2                                [32, 1280, 1, 1]          --\n",
       "├─Sequential: 1-3                                       [32, 38]                  --\n",
       "│    └─Dropout: 2-10                                    [32, 1280]                --\n",
       "│    └─Linear: 2-11                                     [32, 38]                  48,678\n",
       "=========================================================================================================\n",
       "Total params: 4,056,226\n",
       "Trainable params: 48,678\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (Units.GIGABYTES): 12.31\n",
       "=========================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.10\n",
       "Params size (MB): 16.22\n",
       "Estimated Total Size (MB): 3487.59\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Define the Model ---\n",
    "print(\"\\nDefining the model architecture...\")\n",
    "# Load a pre-trained EfficientNet-B0 model\n",
    "model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Freeze all the parameters in the pre-trained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final classifier layer\n",
    "# EfficientNet's classifier is at 'model.classifier[1]'\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(\n",
    "    in_features=num_features, out_features=NUM_CLASSES)\n",
    "\n",
    "# --- Verification ---\n",
    "# Use torchinfo to display a summary of the model\n",
    "# This will show which layers are frozen (not trainable) and which are not.\n",
    "print(\"Model summary:\")\n",
    "summary(model, input_size=(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc73ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up training components...\n",
      "Using device: cpu\n",
      "Loss function and optimizer are set up.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Set up Training Components ---\n",
    "print(\"\\nSetting up training components...\")\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move the model to the selected device\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (only for the unfrozen classifier parameters)\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "print(\"Loss function and optimizer are set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63660316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 5 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Training]: 100%|██████████| 2197/2197 [28:37<00:00,  1.28it/s, loss=0.442] \n",
      "Epoch 1/5 [Validating]: 100%|██████████| 550/550 [06:17<00:00,  1.46it/s, loss=0.394]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 -> Train Loss: 0.4741, Train Accuracy: 0.8947 | Validation Loss: 0.1765, Validation Accuracy: 0.9499\n",
      "-> New best model saved to 'best_crop_doctor_model.pth' with accuracy: 0.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Training]: 100%|██████████| 2197/2197 [19:55<00:00,  1.84it/s, loss=0.149] \n",
      "Epoch 2/5 [Validating]: 100%|██████████| 550/550 [04:20<00:00,  2.11it/s, loss=0.286]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 -> Train Loss: 0.2032, Train Accuracy: 0.9394 | Validation Loss: 0.1309, Validation Accuracy: 0.9606\n",
      "-> New best model saved to 'best_crop_doctor_model.pth' with accuracy: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Training]: 100%|██████████| 2197/2197 [22:40<00:00,  1.62it/s, loss=0.136] \n",
      "Epoch 3/5 [Validating]: 100%|██████████| 550/550 [04:19<00:00,  2.12it/s, loss=0.0798]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 -> Train Loss: 0.1756, Train Accuracy: 0.9454 | Validation Loss: 0.1178, Validation Accuracy: 0.9627\n",
      "-> New best model saved to 'best_crop_doctor_model.pth' with accuracy: 0.9627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Training]: 100%|██████████| 2197/2197 [20:52<00:00,  1.75it/s, loss=0.185]  \n",
      "Epoch 4/5 [Validating]: 100%|██████████| 550/550 [04:10<00:00,  2.19it/s, loss=0.171]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 -> Train Loss: 0.1572, Train Accuracy: 0.9502 | Validation Loss: 0.1116, Validation Accuracy: 0.9636\n",
      "-> New best model saved to 'best_crop_doctor_model.pth' with accuracy: 0.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Training]: 100%|██████████| 2197/2197 [22:23<00:00,  1.64it/s, loss=0.459]  \n",
      "Epoch 5/5 [Validating]: 100%|██████████| 550/550 [04:53<00:00,  1.87it/s, loss=0.138]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 -> Train Loss: 0.1518, Train Accuracy: 0.9507 | Validation Loss: 0.0950, Validation Accuracy: 0.9685\n",
      "-> New best model saved to 'best_crop_doctor_model.pth' with accuracy: 0.9685\n",
      "\n",
      "Training complete!\n",
      "Best validation accuracy: 0.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Run the Training Loop ---\n",
    "NUM_EPOCHS = 5  # Let's start with 5 epochs\n",
    "best_val_accuracy = 0.0\n",
    "model_save_path = '../best_crop_doctor_model.pth'\n",
    "\n",
    "print(f\"\\nStarting training for {NUM_EPOCHS} epochs...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # --- Training Phase ---\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    train_preds, train_labels = [], []\n",
    "\n",
    "    train_progress_bar = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Training]\")\n",
    "    for inputs, labels in train_progress_bar:\n",
    "        # Move data to the device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Update progress bar\n",
    "        train_progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():  # No need to calculate gradients during validation\n",
    "        val_progress_bar = tqdm(\n",
    "            val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Validating]\")\n",
    "        for inputs, labels in val_progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} -> \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} | \"\n",
    "          f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model if it has the best validation accuracy so far\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(\n",
    "            f\"-> New best model saved to '{model_save_path}' with accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723a9d8",
   "metadata": {},
   "source": [
    "Testing on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adfcde09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data and preparing the DataLoader...\n",
      "Filtered out 33 rows with invalid labels (like 'test').\n",
      "Test data ready. Found 0 valid images.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Prepare the Test Data (Corrected with Filtering) ---\n",
    "print(\"Loading test data and preparing the DataLoader...\")\n",
    "\n",
    "# Load the test DataFrame\n",
    "test_df = pd.read_parquet(os.path.join(PROCESSED_DATA_DIR, 'test.parquet'))\n",
    "\n",
    "# Get the list of valid, known class names from our mapping\n",
    "valid_labels = class_to_idx.keys()\n",
    "\n",
    "# **FILTERING STEP:** We only keep the rows in test_df that have a valid label.\n",
    "original_size = len(test_df)\n",
    "test_df_filtered = test_df[test_df['label'].isin(valid_labels)]\n",
    "new_size = len(test_df_filtered)\n",
    "\n",
    "if original_size != new_size:\n",
    "    print(\n",
    "        f\"Filtered out {original_size - new_size} rows with invalid labels (like 'test').\")\n",
    "\n",
    "# Create the test dataset using the FILTERED dataframe\n",
    "test_dataset = PlantVillageDataset(\n",
    "    test_df_filtered, class_to_idx, transform=val_test_transforms)\n",
    "\n",
    "# Create the test DataLoader\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Test data ready. Found {len(test_dataset)} valid images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d9dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from '../best_crop_doctor_model.pth' and set to evaluation mode.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load the Best Model ---\n",
    "\n",
    "# Re-create the model architecture\n",
    "# It must be the same architecture as the one we trained\n",
    "# We don't need pre-trained weights now\n",
    "model = models.efficientnet_b0(weights=None)\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(\n",
    "    in_features=num_features, out_features=NUM_CLASSES)\n",
    "\n",
    "# Define the path to the saved model\n",
    "model_path = '../best_crop_doctor_model.pth'\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Move the model to the correct device\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "# This is important as it disables layers like Dropout\n",
    "model.eval()\n",
    "\n",
    "print(\n",
    "    f\"Model loaded successfully from '{model_path}' and set to evaluation mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f779dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on the test set complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Run Evaluation on the Test Set ---\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "print(\"\\nMaking predictions on the test set...\")\n",
    "\n",
    "# We use torch.no_grad() to speed up inference and save memory\n",
    "with torch.no_grad():\n",
    "    # Wrap the test_loader with tqdm for a progress bar\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get the predicted class (the one with the highest score)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Append predictions and true labels to our lists\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Prediction on the test set complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61cfb206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating model performance on the VALIDATION set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Validation: 100%|██████████| 550/550 [05:32<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Accuracy (on validation set): 96.85%\n",
      "\n",
      "Detailed Classification Report (on Validation Set):\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                          Apple_scab       0.97      0.96      0.97       504\n",
      "                           Black_rot       0.99      0.99      0.99       497\n",
      "                    Cedar_apple_rust       0.98      0.97      0.98       440\n",
      "                             healthy       0.96      0.98      0.97       502\n",
      "                             healthy       0.98      0.98      0.98       454\n",
      "                             healthy       0.98      1.00      0.99       456\n",
      "                      Powdery_mildew       0.97      0.99      0.98       421\n",
      " Cercospora_leaf_spot Gray_leaf_spot       0.96      0.85      0.90       410\n",
      "                        Common_rust_       0.99      0.99      0.99       477\n",
      "                             healthy       0.99      1.00      1.00       465\n",
      "                Northern_Leaf_Blight       0.87      0.96      0.92       477\n",
      "                           Black_rot       0.98      0.98      0.98       472\n",
      "                Esca_(Black_Measles)       0.98      0.99      0.99       480\n",
      "                             healthy       1.00      1.00      1.00       423\n",
      "  Leaf_blight_(Isariopsis_Leaf_Spot)       0.99      0.98      0.99       430\n",
      "     Haunglongbing_(Citrus_greening)       0.98      1.00      0.99       503\n",
      "                      Bacterial_spot       0.98      0.96      0.97       459\n",
      "                             healthy       0.98      0.99      0.99       432\n",
      "                      Bacterial_spot       0.98      0.98      0.98       478\n",
      "                             healthy       0.97      0.98      0.97       497\n",
      "                        Early_blight       0.99      1.00      0.99       485\n",
      "                             healthy       0.97      0.97      0.97       456\n",
      "                         Late_blight       0.98      0.97      0.97       485\n",
      "                             healthy       1.00      0.99      0.99       445\n",
      "                             healthy       0.97      0.99      0.98       505\n",
      "                      Powdery_mildew       0.99      1.00      1.00       434\n",
      "                             healthy       1.00      1.00      1.00       456\n",
      "                         Leaf_scorch       1.00      1.00      1.00       444\n",
      "                      Bacterial_spot       0.94      0.96      0.95       425\n",
      "                        Early_blight       0.88      0.92      0.90       480\n",
      "                             healthy       0.97      0.98      0.97       481\n",
      "                         Late_blight       0.91      0.91      0.91       463\n",
      "                           Leaf_Mold       0.96      0.93      0.95       470\n",
      "                  Septoria_leaf_spot       0.91      0.90      0.90       436\n",
      "Spider_mites Two-spotted_spider_mite       0.96      0.92      0.94       435\n",
      "                         Target_Spot       0.94      0.87      0.90       457\n",
      "                 Tomato_mosaic_virus       0.98      0.98      0.98       448\n",
      "       Tomato_Yellow_Leaf_Curl_Virus       0.97      0.98      0.98       490\n",
      "\n",
      "                            accuracy                           0.97     17572\n",
      "                           macro avg       0.97      0.97      0.97     17572\n",
      "                        weighted avg       0.97      0.97      0.97     17572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL EVALUATION ON THE VALIDATION SET ---\n",
    "# Since the test set has label mismatches, we will use the validation\n",
    "# set for our final performance report.\n",
    "\n",
    "print(\"--- Evaluating model performance on the VALIDATION set ---\")\n",
    "\n",
    "# We will use the val_loader which we know is working correctly\n",
    "val_preds = []\n",
    "val_labels = []\n",
    "\n",
    "model.eval()  # Make sure the model is in evaluation mode\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Final Validation\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# --- Calculate and Display Final Metrics ---\n",
    "# Calculate overall accuracy on the validation set\n",
    "final_val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "print(\n",
    "    f\"\\nFinal Model Accuracy (on validation set): {final_val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Generate the detailed classification report\n",
    "idx_to_class = {i: label for label, i in class_to_idx.items()}\n",
    "class_names = [idx_to_class[i].split('___')[1] for i in range(NUM_CLASSES)]\n",
    "\n",
    "report = classification_report(\n",
    "    val_labels,\n",
    "    val_preds,\n",
    "    target_names=class_names\n",
    ")\n",
    "\n",
    "print(\"\\nDetailed Classification Report (on Validation Set):\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98440694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Test Data with Corrected File Name Parsing ---\n",
      "Successfully parsed 17 images from the test folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL REPORT ---\n",
      "Overall Test Accuracy: 82.35%\n",
      "\n",
      "Detailed Classification Report (on Test Set):\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                          Apple_scab       0.00      0.00      0.00         0\n",
      "                           Black_rot       0.00      0.00      0.00         0\n",
      "                    Cedar_apple_rust       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                      Powdery_mildew       0.00      0.00      0.00         0\n",
      " Cercospora_leaf_spot Gray_leaf_spot       0.00      0.00      0.00         0\n",
      "                        Common_rust_       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                Northern_Leaf_Blight       0.00      0.00      0.00         0\n",
      "                           Black_rot       0.00      0.00      0.00         0\n",
      "                Esca_(Black_Measles)       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "  Leaf_blight_(Isariopsis_Leaf_Spot)       0.00      0.00      0.00         0\n",
      "     Haunglongbing_(Citrus_greening)       0.00      0.00      0.00         0\n",
      "                      Bacterial_spot       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                      Bacterial_spot       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                        Early_blight       1.00      1.00      1.00         5\n",
      "                             healthy       1.00      1.00      1.00         2\n",
      "                         Late_blight       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                      Powdery_mildew       0.00      0.00      0.00         0\n",
      "                             healthy       0.00      0.00      0.00         0\n",
      "                         Leaf_scorch       0.00      0.00      0.00         0\n",
      "                      Bacterial_spot       0.00      0.00      0.00         0\n",
      "                        Early_blight       1.00      0.67      0.80         6\n",
      "                             healthy       1.00      0.75      0.86         4\n",
      "                         Late_blight       0.00      0.00      0.00         0\n",
      "                           Leaf_Mold       0.00      0.00      0.00         0\n",
      "                  Septoria_leaf_spot       0.00      0.00      0.00         0\n",
      "Spider_mites Two-spotted_spider_mite       0.00      0.00      0.00         0\n",
      "                         Target_Spot       0.00      0.00      0.00         0\n",
      "                 Tomato_mosaic_virus       0.00      0.00      0.00         0\n",
      "       Tomato_Yellow_Leaf_Curl_Virus       0.00      0.00      0.00         0\n",
      "\n",
      "                            accuracy                           0.82        17\n",
      "                           macro avg       0.11      0.09      0.10        17\n",
      "                        weighted avg       1.00      0.82      0.90        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# --- FINAL EVALUATION (Corrected Parsing Logic) ---\n",
    "\n",
    "print(\"--- Preparing Test Data with Corrected File Name Parsing ---\")\n",
    "\n",
    "\n",
    "def create_test_df_from_filenames_corrected(directory, train_labels_map):\n",
    "    \"\"\"\n",
    "    Parses a flat directory of test images where the label is in the filename.\n",
    "    This version correctly handles the mapping logic.\n",
    "    \"\"\"\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    # **THE FIX IS HERE:** This map now correctly includes the crop name.\n",
    "    # e.g., 'Potato___Early_blight' -> 'potatoearlyblight'\n",
    "    simple_name_map = {\n",
    "        label.replace('___', '').replace('_', '').lower(): label\n",
    "        for label in train_labels_map\n",
    "    }\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "\n",
    "            # This parsing logic is correct.\n",
    "            # \"PotatoEarlyBlight1.jpg\" -> \"potatoearlyblight\"\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            label_part = re.sub(\n",
    "                r'\\d+$', '', base_name).replace('_', '').lower()\n",
    "\n",
    "            # Now, it will correctly find 'potatoearlyblight' in the map\n",
    "            full_label = simple_name_map.get(label_part)\n",
    "\n",
    "            if full_label:\n",
    "                filepaths.append(filepath)\n",
    "                labels.append(full_label)\n",
    "\n",
    "    return pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "\n",
    "# 1. Define paths and get known labels\n",
    "TEST_PATH = '../data/plantvillage_raw/test'\n",
    "known_labels = class_to_idx.keys()\n",
    "\n",
    "# 2. Create the test DataFrame using the CORRECTED custom function\n",
    "test_df = create_test_df_from_filenames_corrected(TEST_PATH, known_labels)\n",
    "\n",
    "print(f\"Successfully parsed {len(test_df)} images from the test folder.\")\n",
    "\n",
    "# 3. Create the test_dataset and test_loader\n",
    "test_dataset = PlantVillageDataset(\n",
    "    test_df, class_to_idx, transform=val_test_transforms)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# 4. Load the best model\n",
    "model.load_state_dict(torch.load('../best_crop_doctor_model.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 5. Make predictions\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 6. Display the final report\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "print(f\"\\n--- FINAL REPORT ---\")\n",
    "print(f\"Overall Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "class_names = [idx_to_class[i].split('___')[1] for i in range(NUM_CLASSES)]\n",
    "report = classification_report(\n",
    "    test_labels,\n",
    "    test_preds,\n",
    "    target_names=class_names,\n",
    "    labels=range(NUM_CLASSES),\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nDetailed Classification Report (on Test Set):\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3841f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
