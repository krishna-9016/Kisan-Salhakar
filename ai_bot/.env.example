# --- Data and Model Paths ---
KNOWLEDGE_BASE_DIR="data/knowledge_base"
VECTOR_STORE_DIR="vector_store"
FINETUNING_DATASET_PATH="data/finetuning_dataset.json"

# --- Model Configuration ---
# Embedding model for RAG
EMBEDDING_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"

# Base LLM for fine-tuning and inference. 
# IMPORTANT: Choose a Causal (decoder-only) model. distilgpt2 is a small example.
# For better Punjabi performance, consider models like 'ai4bharat/indic-gpt' or other multilingual GPTs.
BASE_MODEL_NAME="distilgpt2"

# Name for the saved LoRA adapter
ADAPTER_MODEL_NAME="punjabi-farmer-advisor-v1"